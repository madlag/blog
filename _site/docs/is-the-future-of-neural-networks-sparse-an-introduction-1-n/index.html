<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="/assets/images/logo.png">

<title>Is the future of Neural Networks Sparse? An Introduction (1/N) | Numbers ∩ Nature</title>

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Is the future of Neural Networks Sparse? An Introduction (1/N) | Numbers ∩ Nature</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Is the future of Neural Networks Sparse? An Introduction (1/N)" />
<meta name="author" content="francois" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="From principles to real-world library support." />
<meta property="og:description" content="From principles to real-world library support." />
<meta property="og:site_name" content="Numbers ∩ Nature" />
<meta property="og:image" content="/assets/images/mdm/sparse_1.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-02-04T00:00:00+01:00" />
<script type="application/ld+json">
{"image":"/assets/images/mdm/sparse_1.png","datePublished":"2020-02-04T00:00:00+01:00","headline":"Is the future of Neural Networks Sparse? An Introduction (1/N)","mainEntityOfPage":{"@type":"WebPage","@id":"/is-the-future-of-neural-networks-sparse-an-introduction-1-n/"},"url":"/is-the-future-of-neural-networks-sparse-an-introduction-1-n/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"/assets/images/logo.png"},"name":"francois"},"author":{"@type":"Person","name":"francois"},"description":"From principles to real-world library support.","@type":"BlogPosting","dateModified":"2020-02-04T00:00:00+01:00","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link href="/assets/css/screen.css" rel="stylesheet">

<link href="/assets/css/main.css" rel="stylesheet">

<script src="/assets/js/jquery.min.js"></script>

</head>




<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="/">
    <img src="/assets/images/logo.png" alt="Numbers ∩ Nature">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">
                 <li class="nav-item">
                <a class="nav-link" href="/about">About</a>
                </li>
<!--

                
                <li class="nav-item">
                
                <a class="nav-link" href="/index.html">Home</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="/about">About</a>
                </li>
                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/wowthemesnet/mediumish-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>
                </li>
!-->
                <script src="/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/assets/js/lunrsearchengine.js"></script>

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">Numbers ∩ Nature</h1>
    <p class="lead">
        A geek stance on AI, physics, and whatever catch my eye
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Is the future of Neural Networks Sparse? An Introduction (1/N)&url=/is-the-future-of-neural-networks-sparse-an-introduction-1-n/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=/is-the-future-of-neural-networks-sparse-an-introduction-1-n/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=/is-the-future-of-neural-networks-sparse-an-introduction-1-n/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
    
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="https://www.gravatar.com/avatar/205c3e49902572f215d99796656526c7?s=250&d=mm&r=x" alt="François Lagunas">
                        
                    </div>
                    <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left">
                        <a target="_blank" class="link-dark" href="https://madlag.github.io">François Lagunas</a><a target="_blank" href="https://twitter.com/madlag" class="btn follow">Follow</a>
                        <span class="author-description">AI Researcher & Entrepreneur & Angel Investor. Space Enthusiast, Sea Lover & Scuba Divemaster.</span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Is the future of Neural Networks Sparse? An Introduction (1/N)</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            <!--
            

            
            <img class="featured-image img-fluid" src="/assets/images/mdm/sparse_1.png" alt="Is the future of Neural Networks Sparse? An Introduction (1/N)">
            

            
            -->

            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <h4 id="from-principles-to-real-world-library-support">From principles to real-world library support.</h4>

<p><img src="/assets/images/mdm/1*7e9p9imPoRBYh5WYF3FFrQ.png" alt="" />TLDR: Yes#### <strong>Hi, I am François Lagunas.</strong></p>

<p>I am doing Machine Learning research, and I have been working for the last months on using sparse matrices, especially in Transformers. The recent <a href="https://openai.com/blog/openai-pytorch/"><strong>announcement</strong></a> that <strong>OpenAI</strong> is porting its <a href="https://openai.com/blog/block-sparse-gpu-kernels/"><strong>block sparse toolbox</strong></a> in <strong>PyTorch</strong> is really big news:</p>

<blockquote>
  <p>“We are in the process of writing PyTorch bindings for our highly-optimized blocksparse kernels, and will open-source those bindings in upcoming months”I was talking about it with the outstanding <a href="https://huggingface.co/">Hugging Face</a> team, (I am one of their early investors), and I wanted to share with you my excitement!</p>
</blockquote>

<h3 id="what-is-a-sparse-matrix">What is a Sparse Matrix?</h3>

<p>A <strong><em>sparse</em></strong> matrix is just a matrix with some zeros. Usually, a lot of them. So every place you are using a <strong><em>dense matrix</em></strong>, in a linear layer, for example, you could be using a sparse one.</p>

<p><img src="/assets/images/mdm/1*tf99LCAMrO70WAO4tkgFBw.png" alt="" />Matrices with increasing sparsityThe <strong><em>sparsity</em></strong> of the matrix is the fraction of zeros against the size of the matrix</p>

<p><strong>The pros?</strong> If you have a lot of zeros, you don’t have to compute some multiplications, and you don’t have to store them. So you <strong><em>may</em></strong> gain on size and speed, for training and inference (more on this today).</p>

<p>**The cons? **Of course, having all these zeros will probably have an impact on network accuracy/performance. But to what extent? You may be surprised.</p>

<h3 id="where-are-they-from">Where are they from?</h3>

<p>The first researchers/engineers to use sparse matrices were <a href="https://en.wikipedia.org/wiki/Finite_element_method">Finite Elements</a> users.</p>

<p><img src="/assets/images/mdm/1*IvRIZEjC7kgUBuozUFlSng.png" alt="" />A 2D mesh (roof of Omni Coliseum, Atlanta) and its finite element matrix (<a href="https://www.cise.ufl.edu/research/sparse/matrices/HB/bcsstk14.html">source</a>).When you have to deal with large physical simulations, you get a large graph of interconnected vertices.</p>

<p>Each vertex is a point of your system, and each edge connects two vertices. That means that these <strong>two points</strong> will have some <strong>influence</strong> on each other in the model. And so there is a <strong>non-zero</strong> value in the matrix that describes the graph.</p>

<p>This last sentence sums it up: you need non-zero values in the matrix when two dimensions are interacting in some way.</p>

<p>**Now getting back to ML, you should ask yourself the same question: are all the dimensions of my input vector interacting with all the others? **Usually not. So going sparse maybe useful.</p>

<p>We have actually a very good, and famous, example of a successful trip to sparse-land: <strong>convolutional layers</strong>.</p>

<p><img src="/assets/images/mdm/1*3WLh11vam1ktq7kWJ9aKpg.jpeg" alt="" />Learned convolutional filters. From <a href="http://cs231n.github.io/convolutional-networks/">http://cs231n.github.io/convolutional-networks/</a>Convolutional layers are a smart and efficient way to implement a sparse transformation on an input tensor.</p>

<p>When processing images, it comes down to two things:</p>

<p><strong>Sparsity</strong>: the transformation is local → each output pixel should depend on a few neighboring input pixels.</p>

<p><strong>Invariance</strong>: the transformation does not depend on the position in the image</p>

<p>Then you just add the constraint that the transformation is linear: if you were to represent this transformation, you would get a HUGE matrix with only a few non-zeros. But of course, the right way to do this is to do a multiplication of the input tensor with a small set of small matrices (each square in the image before).</p>

<p>The importance of convolutions in today’s ML success is obvious. But you can see that <strong>finding a clever way to make things sparse sounds like a good recipe to save time and space.</strong></p>

<h3 id="where-are-they-useful">Where are they useful?</h3>

<p>Convolutions are already an efficient form of sparsity, so you could try to make them <a href="https://arxiv.org/abs/1902.05967">even</a> more <a href="http://arxiv.org/abs/1907.04840">sparse</a>, but some other networks contain much larger matrices that may benefit from sparsity: Transformers.</p>

<p>And those are getting bigger and bigger. We have greatly exceeded the 1 billion parameters in 2019, and it’s not stopping here. The cost to train and to use those networks is getting unpractical, so every method to reduce their size will be welcome.</p>

<p><img src="/assets/images/mdm/0*m3oTlwLmwuXuBCVg.jpg" alt="" />From <a href="https://devblogs.nvidia.com/training-bert-with-gpus/">https://devblogs.nvidia.com/training-bert-with-gpus/</a>### Why the OpenAI announcement is so important?</p>

<p>So, if everything is fine in sparse-land, we should all be trying sparse matrices, shouldn’t we?</p>

<p>Yes. But there is this stupid thing called <strong>implementation</strong>. It’s easy to see the theoretical improvements we could get with sparse compute. But the support in libraries is quite … sparse.</p>

<p>PyTorch <a href="https://github.com/soumith">developers</a>, for example, have done a <strong>significant</strong> <strong>effort</strong> to support sparse compute. But there is still a big gap in performance between dense and sparse matrices operations, which defeats the whole purpose of using them. Even memory usage is quite large: sparsity has to be more than 80% to save some room on sparse matrices (more on that in my next post). Even basic serialization was broken before version 1.4. The reason is that the underlying libraries (for example cuSPARSE) are not doing a great job because the problem is ill-suited to the way GPU works.</p>

<p>So the <strong>OpenAI</strong> <strong>announcement</strong> on their block sparse tools is <strong>very</strong> <strong>good</strong> <strong>news</strong> for those who want to use sparse ops without sacrificing training speed (and it looks like some <a href="https://github.com/openai/blocksparse/issues/2">people</a> have been waiting for some time now). And we are not talking about a few percents.</p>

<blockquote>
  <p>“Our kernels typically performed <strong>one or two orders of magnitude faster</strong> in terms of GFLOPS.”<img src="/assets/images/mdm/1*qXMoK7emiT7J6CA_3O29_A.png" alt="" />From OpenAI <a href="https://d4mucfpksywv.cloudfront.net/blocksparse/blocksparsepaper.pdf">blocksparse paper</a>(The worst thing is that the <a href="https://d4mucfpksywv.cloudfront.net/blocksparse/blocksparsepaper.pdf">paper</a> concludes that cuBLAS is faster that cuSPARSE even with very sparse matrices. How sad.)</p>
</blockquote>

<p>The magic keyword here is “<strong>block</strong>”. <strong>It’s hard to implement general sparse matrice computations on GPUs in an efficient way</strong>. But it gets much easier if you add a “reasonable” constraint on the form of the matrices: their non-zeros should be grouped in small fixed-size blocks, and that makes GPU processing much easier to parallelize efficiently. Typically 8x8, 16x16 or 32x32 blocks, 16x16 already giving a very good performance, with 32x32 giving a slightly better one.</p>

<p><img src="/assets/images/mdm/1*rHFMCfJ8Td-vhJi0e0zAQw.png" alt="" />A 8-block-sparse matriceOf course, the “block” constraint may be crippling some sparsification algorithms, or at least it would require some changes to take it into account.</p>

<p>But at least we can play with large high sparsity matrices, and the block constraint may not be a big issue: if you think about it, it means that there is <strong>some locality in the dimensions</strong>, and that sounds a quite reasonable constraint. That’s the same reason band matrices have been useful in the past (finite difference, finite elements), and it was a much stronger constraint.</p>

<p><img src="/assets/images/mdm/1*zknKSiBQpsppvjDJFIFbqw.png" alt="" />Band matrix### Conclusion</p>

<p>I hope I have convinced you that 2020 will be the sparse network year (it already has two zeros, that’s a sign).</p>

<p><strong>Next time **for those who are curious about what happens when they are using some CUDA based PyTorch code, we’ll dig a bit deeper in **GPU internals</strong>, (and we will understand** why block sparse code is outrunning sparse code by a large margin**).</p>

<p><strong>This article series will continue on the different techniques that have been proposed to make sparse networks, and what are the potential long term benefits.</strong></p>

<h4 id="more-reading">More reading</h4>

<p>First, here is a <a href="https://towardsdatascience.com/sparse-matrices-in-pytorch-part-2-gpus-fd9cc0725b71"><strong>study</strong></a>** of PyTorch sparse performance.**</p>

<p>If you want to have a very detailed review of <strong>different complementary approaches to network size reduction</strong>, and not just about sparse ones, you should definitely read <a href="http://mitchgordon.me/machine/learning/2020/01/13/do-we-really-need-model-compression.html">this article</a>.</p>

<p>And if you want to <strong>create illustrations like the header of this blog post</strong>, you will find the code I used on my <a href="https://github.com/madlag/medium_posts/tree/master/sparse_matrices_1"><strong>github</strong></a>.</p>


            </div>

            <!-- Rating -->
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2020-02-04">04 Feb 2020</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/tags#AI">#AI</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/tags#NLP">#NLP</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            
            <a class="next d-block col-md-6 text-lg-right" href="//how-can-we-contain-the-coronavirus/">How can we contain the coronavirus? &raquo; </a>
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

</div>


    
</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2020 François Lagunas
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="https://www.wowthemes.net/mediumish-free-jekyll-template/">Mediumish Jekyll Theme</a> by WowThemes.net
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/assets/js/mediumish.js"></script>



<script src="/assets/js/ie10-viewport-bug-workaround.js"></script> 


<script id="dsq-count-scr" src="//.disqus.com/count.js"></script>


</body>
</html>
